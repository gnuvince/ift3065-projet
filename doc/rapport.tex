\documentclass[11pt]{report}

\usepackage{times}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{parskip}
\usepackage{multicol}
\usepackage{url}
\usepackage{syntax}

\begin{document}

\newcommand{\sins}{\emph{SINS}}
\newcommand{\bop}{\textbf{(}}
\newcommand{\bcp}{\textbf{)}}

\title{IFT3065 - Rapport sur SINS}
\author{Vincent Foley-Bourgon (FOLV08078309) \\
Eric Thivierge (THIE09016601)}
\maketitle

\abstract

\sins{} (Scheme IN Scheme) est un compilateur Scheme écrit dans le
langage Scheme dans le cadre du cours IFT3065 de la session hiver 2012
à l'Université de Montréal.  Ce rapport décrit la philosophie
directrice du projet, les différentes parties du compilateur, les
problèmes et difficultés rencontrés durant son écriture et les
solutions mises en place pour résoudre ces problèmes.

\chapter{SINS}

\section{Qu'est-ce que SINS?}

\sins{} (Scheme IN Scheme) est un petit compilateur Scheme écrit
dans le cadre d'un cours de compilation de 15 semaines.  Comme son nom
l'indique, il s'agit d'un compilateur pour Scheme écrit en Scheme.
\sins{} génère du code assembleur x86.

\sins{} est un véhicule permettant à ses auteurs de faire un survol
des différents aspects de la compilation. Notre philosophie de base
est qu'étant donné le choix d'implanter une fonctionnalité en
profondeur ou d'en implanter deux avec des techniques moins
sophistiquées, nous choisirons la deuxième option à tout coup. Nous
sommes d'avis que cette approche nous donnera une vision plus globale
d'un compilateur. Les détails d'implantation plus avancés pourront
être appris, implantés et maîtrisés dans le cadre de stages, de
projets personnels, de recherches et d'emplois.


\section{Design de SINS}

\sins{} suit un modèle en pipeline où chaque étape de la compilation a
son propre module et où chaque module a comme entrée la sortie du
module précédent. Chaque module effectue (si possible) une seule
transformation afin de garder la complexité du module la plus minimale
possible. Cela implique que \sins{} fait plus de passes sur le code et
qu'il est plus lent à l'exécution qu'un compilateur qui fusionne
plusieurs phases en une. Dans le cadre d'un projet éducationnel, nous
jugeons que cette contrainte est acceptable.


\chapter{Analyse lexicale}

La première phase habituelle d'un compilateur est de transformer un
flux de caractères représentant un programme source en un flux de
lexèmes.  Dans ce flux sortant, les espaces blancs et les commentaires
sont éliminés, et les caractères représentant des nombres ou des mots
sont regroupés ensemble pour une analyse syntaxique plus facile.

Il existe de nombreux outils automatisés qui permettent de faire
l'analyse lexicale; \emph{lex}, \emph{flex} et \emph{silex} sont de
tels outils.  Malgré leur disponibilité, nous avons décidé de ne pas
utiliser ces outils et de plutôt créer notre propre analyseur lexical.
Cette décision a été prise afin de mieux comprendre les détails de
plus bas niveau, ainsi que les difficultés d'implantation de cette
phase.

La grammaire reconnue par l'analyse lexicale de \sins{} est décrite
dans la section \ref{grammar-tokens}.

\section{Structures de données}

Afin de faire l'analyse lexicale d'un programme source, deux
structures de données principales sont nécessaires: un type flux
(\emph{stream}), et un type lexème (\emph{token}).

\subsection{Stream}

La fonction \emph{make-stream} prend en entrée une chaîne de
caractères et retourne un \emph{stream}.  La fonction
\emph{make-stream-from-port} prend en entrée un port d'entrée et
retourne un \emph{stream}.  Un \emph{stream} est une structure de
données possédant les 4 opérations suivantes:

\begin{itemize}
\item {\bf next}: cette fonction retourne le caractère courant du
  flux.  Si le flux est terminé, elle retourne le caractère nul.
\item {\bf advance}: cette fonction fait avancer le curseur d'un
  caractère dans le flux et met à jour les attributs \emph{line} et
  \emph{col}.  \emph{Advance} n'a pas de valeur de retour.
\item {\bf line}: retourne la ligne courante.
\item {\bf col}: retourne la colonne courante.
\end{itemize}

\subsection{Token}

Un lexème est représenté par une liste ayant la forme suivante:

\begin{verbatim}
(token (<type> . <valeur>) <ligne> <colonne>)
\end{verbatim}

Le premier élément est une étiquette qui permet de distinguer un
lexème d'un autre type de données.  La paire en deuxième position
donne l'information sur le type du lexème (ex.: mot-clé,
identificateur, etc.) et la valeur qui lui est associée.  Les
troisième et quatrième champs conservent la position du début du
lexème.

Une erreur dans un lexème (par exemple: constante de caractère
invalide) est représentée par une liste ayant la forme suivante:

\begin{verbatim}
(token-error <ligne> <colonne>)
\end{verbatim}


On peut manipuler les lexèmes à l'aide des fonctions suivantes:

\begin{itemize}
\item {\bf make-token}: cette fonction permet de créer un lexème en
  donnant son type et sa valeur, sa ligne, et sa colonne.  Si
  type/valeur est \#f, \emph{make-token} retourne un erreur de lexème.
\item {\bf token?}: un prédicat qui détermine si un objet représente
  un lexème.
\item {\bf token-error?}: un prédicat qui détermine si un objet
  représente une erreur dans un lexème.
\item {\bf token-type}: retourne le type du lexème.
\item {\bf token-value}: retourne la valeur du lexème.
\item {\bf token-symbol}: retourne le type et la valeur d'un lexème.
\item {\bf token-line}: retourne la ligne où commence ce lexème.
\item {\bf token-col}: retourne la colonne où commence ce lexème.
\end{itemize}

\section{Algorithme d'analyse}

La fonction \emph{get-token} prend en entrée un flux de caractères et
retourne le prochain lexème.  Voici une explication de son
fonctionnement.

Tout d'abord, \emph{get-token} commence par ignorer les espaces blancs
et les commentaires.  Une fois que le flux se trouve sur un caractère
non-blanc, on effectue une analyse de cas.  Si le caractère courant
est un des terminaux suivants du langage, on retourne un lexème
représentant ce symbole: \texttt{(}, \texttt{)}, \texttt{,},
\texttt{,@}, \texttt{'}, \texttt{`}, et le caractère nul.

Dans le cas où le caractère est un guillemet, on accumule les
caractères du flux jusqu'à ce qu'on consomme le guillemet fermant (en
faisant attention aux séquences d'échappement).

Dans le cas où le caractère est un dièse, on essaye de lire, en ordre,
la constante vraie (\#t), la constante fausse (\#f) ou un caractère
(\#\textbackslash).  Dans le cas du caractère, si le caractère suivant
le backslash n'est pas alphabétique, on retourne immédiatement le code
ASCII de ce caractère.  Si le caractère est alphabétique, on tente de
lire un nom de caractère.  Nous supportons les noms ``nul'', ``tab'',
``space'' et ``newline''.  Si le nom possède un seul caractère, on
retourne le code ASCII associé à ce caractère.  Dans tous les autres
cas, on retourne \#f pour signaler une erreur.

Si le caractère est un chiffre, on lit un nombre.  Cela empêche des
identificateurs débutant par un chiffre comme \emph{2pi} par exemple.
Cette limitation est acceptable dans notre compilateur (et est
conforme avec la syntaxe décrite dans la section 7.1.1 du standard
R5RS).

Dans le cas où le caractère est un caractère qui fait partie de
l'alphabet des identificateurs, on procède en deux étapes:

\begin{enumerate}
\item On lit tous les caractères identificateurs;
\item On classifie le symbole et construisons le lexème approprié.
\end{enumerate}

Si le symbole représente un mot clé, on retourne un lexème de type
\emph{keyword}; autrement, on retourne un lexème de type
identificateur.

Finalement, pour tous les autres caractères, on retourne une erreur de
lexème.

La fonction \emph{lex} permet de prendre en entrée un flux de
caractères et de retourner une liste de lexèmes.  Les fonctions
\emph{lex-from-string} et \emph{lex-from-file} créent un flux à partir
d'une chaîne de caractères et d'un fichier source respectivement et
font ensuite appel à \emph{lex}.


\chapter{Analyse syntaxique}

Tout comme l'analyse lexicale, il existe de nombreux outils pour faire
l'analyse syntaxique d'un flux de lexèmes; Yacc, Bison, LALR-SCM et
ANTLR sont de tels outils.  Et tout comme pour la phase d'analyse
lexicale, afin de mieux comprendre les détails d'implantation de cette
phase et les difficultés qui y sont associées, nous avons décidé de ne
pas utiliser un de ces outils et de plutôt créer notre propre module
d'analyse syntaxique.

Comme la syntaxe de Scheme est simple et peut être exprimée par une
grammaire LL(1), il est naturel de créer cette phase par descente
récursive.  De plus, comme la récursion est omniprésente en Scheme et
que le langage possède des symboles, Scheme est un très bon choix pour
faire cette phase.

Les sections suivantes décriront les différentes phases de l'analyse
syntaxique, les structures de données utilisées ainsi que certains
détails d'implantation que nous jugeons intéressants.

La grammaire reconnue par \sins{} est décrite dans l'annexe
\ref{grammaire}.


\section{Le lecteur}

Une caractéristique propre aux langages Lisp est le lecteur
(\emph{reader} en anglais); le lecteur prend en entrée une chaîne de
caractères représentant une structure Lisp et retourne la
représentation arborescente de cette structure.

Dans cette phase, les symboles sont auto-évalués (et non pas traités
comme des variables) et les listes sont vues non pas comme des appels
de fonctions ou des formes spéciales, mais simplement comme des listes
de symboles.  Voici un exemple d'interaction avec la fonction
\emph{read} dans l'interpréteur de Gambit:

\begin{verbatim}
> (read (open-input-string "allo"))
allo
> (read (open-input-string "(lambda)"))
(lambda)
> (read (open-input-string "(sins est un (bon) compilateur)"))
(sins est un (bon) compilateur)
\end{verbatim}

Les seules vérifications syntaxiques faites par le lecteur sont de s'assurer
que le parenthèsage des expressions est correct et que les listes (propres et
impropres) sont bien formées.  Aucune vérification syntaxique plus approfondie
n'est faite (ex.: qu'une forme lambda soit suivie d'une liste de paramètres
puis d'expressions à exécuter).  Ceci est nécessaire pour la prochaine phase
de l'analyse syntaxique, l'expansion des macros.

Après l'analyse lexicale nous avons une structure de lexèmes; après la phase
de lecture des lexèmes, nous avons une structure arborescente sémantiquement
équivalente au programme source. Nous appelons cette structure arbre de
syntaxe abstraite (AST).

\subsection{Structures de données}

Tout comme l'analyse lexicale, le lecteur possède une flux de
données.  Cette fois, ce sont des lexèmes qui passent sur le flux de
données.  Les opérations suivantes sont supportées:

\begin{itemize}
\item {\bf empty}: retourne vrai ou faux si le flux est vide ou terminé.
\item {\bf next}: retourne le prochain lexème sans modifier le flux.
  Si le flux est vide, la liste vide est retournée.
\item {\bf advance}: consomme le lexème actuel et déplace le flux au
  prochain lexème.  Aucune donnée n'est retournée.
\item {\bf pop}: consomme le lexème actuel et déplace le flux au
  prochain lexème.  Le lexème consommé est retourné.
\end{itemize}

\section{Vérification de l'AST}

Tandis que le lecteur fait une vérification de la forme externe du programme
(le parenthèsage), le parseur effectue la vérification des formes internes du
programme. Par exemple, le parseur vérifie qu'une lambda expression est formée
du mot clé ``lambda'', suivi soit d'un identificateur, soit d'une liste
d'identificateurs (possiblement vide), suivi d'une ou plusieurs expressions.

\subsection{Structures de données}

\sins{} représente l'AST sous forme de listes imbriquées de symboles. Nous
avons choisi cette représentation pour sa simplicité, son faible coût en
mémoire et la facilité de manipulation de cette structure en Scheme.

Afin de garder l'implantation du compilateur plus simple, nous avons
décidé de ne pas inclure les informations relatives aux lignes et
colonnes dans l'AST. Cette décision donnera des messages d'erreur
moins précis, mais nous jugeons que la simplicité gagnée par ce
compromis est plus importante dans le cadre d'un projet pédagogique.

\subsection{Algorithmes}

Nous avons choisi une forme déclarative pour le parseur où chaque fonction
correspond à une production de la grammaire de Scheme (R5RS). La fonction
principale \emph{parse} reçoit une liste d'expressions formant le programme à
vérifier.

Chaque fonction représentant un production reçoit en paramètre un AST à
vérifier et teste séquentiellement les alternatives de cette production en
relation avec l'AST. Si l'une des production unifie l'AST, la fonction retourne
l'AST. Sinon elle retourne faux.

Cette forme déclarative pour le parseur donne au code une structure
claquée sur les productions de la grammaire; cela rend le programme
facile à valider et à maintenir.


\chapter{Conversion}

\section{Simplification}

Afin de diminuer l'effort de génération de code, nous avons implanté
un module de simplification ({\tt src/frontend/conversion.scm}). Ce
module prend l'AST du programme d'entrée et retourne un AST dans
lequel nous avons substitué certaines formes à des formes plus
simples. La procédure de simplification est appliquée récursivement
jusqu'à ce qu'il ne reste que des formes simplifiées.

\subsection{\tt begin}

La forme {\tt (begin $e_1$ $e_2$ ... $e_n$)} est remplacée par une
série de {\tt let} imbriqués.


\begin{verbatim}
(begin e1) => e1
(begin e1 e2) => (let ((:g1 e1)) e2)
(begin e1 e2 e3) => (let ((:g1 e1)) (let ((:g2 e2)) e3))
\end{verbatim}

(Les symboles {\tt :g1}, etc. sont générés automatiquement et sont
uniques.)

\subsection{\tt let}

La forme {\tt let} avec étiquette est transformée en une forme {\tt
  letrec} (nous verrons plus tard que {\tt letrec} est transformée
en {\tt let} sans étiquette).

\begin{verbatim}
(let t () e1) => (letrec ((t (lambda () e1))) (t))
(let t ((a x)) e1) => (letrec ((t (lambda (a) e1))) (t x))
\end{verbatim}


\subsection{\tt let*}

La forme {\tt let*} est transformée en une imbrication de {\tt let}.

\begin{verbatim}
(let* () e1) => e1
(let* ((a x)) e1) => (let ((a x)) e1)
(let* ((a x) (b a)) e1) => (let ((a x)) (let ((b a)) e1))
\end{verbatim}


\subsection{\tt letrec}

La forme {\tt letrec} est transformée en un {\tt let} où on modifie la
valeurs des variables dans le corps du {\tt let}.

\begin{verbatim}
(letrec () e1) => e1
(letrec ((f x)) e1) => (let ((f #f)) (set! f x) e1)
(letrec ((f x) (g y)) e1) =>
   (let ((f #f) (g #f)) (set! f x) (set! g y) e1)
\end{verbatim}


\subsection{\tt lambda}

Le corps d'une forme {\tt lambda} est transformé en un {\tt begin}.

\begin{verbatim}
(lambda () e1) => (lambda () e1)
(lambda () e1 e2) => (lambda () (begin e1 e2))
\end{verbatim}


\subsection{\tt cond}

La forme {\tt cond} est transformée en une imbrication de {\tt if}.


\begin{verbatim}
(cond (else 3)) => 3
(cond (p1 1) (else 3)) => (if p1 1 3)
(cond (p1 1) (p2 2) (else 3)) => (if p1 1 (if p2 2 3))
\end{verbatim}


\subsection{\tt case}

La forme {\tt case} est transformée en une imbrication de {\tt if} et
de {\tt memv}. L'expression sur laquelle on fait le test est évaluée
une seule fois et son résultat est sauvegardé, donc si une expression
a des effets de bords, ceux-ci sont exécutés une seule fois.


\begin{verbatim}
(case x (else 3)) => 3
(case x ((1) 1) (else 3)) =>
   (let ((:g1 x)) (if (memv x (1)) 1 3))
(case x ((1) 1) ((2) 2) (else 3)) =>
   (let ((:g1 x))
     (if (memv :g1 (1))
         1
         (let ((:g2 :g1))
           (if (memv :g2 (2))
               2
               3))))
\end{verbatim}

\subsection{\tt or}

La forme {\tt or} est transformée en une imbrication de {\tt if}; le
résultat de chaque expression est sauvegardé dans une variable afin
d'éviter d'évaluer plusieurs fois les expressions.


\begin{verbatim}
(or) => #f
(or e1) => e1
(or e1 e2) => (let ((:g1 e1)) (if :g1 :g1 e2))
\end{verbatim}

\subsection{\tt and}

La forme {\tt and} est transformée en une imbrication de {\tt if}.


\begin{verbatim}
(and) => #t
(and e1) => e1
(and e1 e2) => (if e1 (if e2 e2 #f) #f)
\end{verbatim}


\section{Alpha conversion}

Afin de faciliter la traduction de Scheme vers assembleur et d'éviter
les conflits de nom, l'AST du programme est passée dans une fonction
qui renomme tous les identificateurs à des noms uniques.  Le programme
résultat est équivalent, mais chaque symbole a un usage unique.

Nous avons trouvé un bogue important dans le module d'alpha
conversion: il plantait pour les lambdas avec un paramètre reste.  En
effet, la fonction {\tt map} ne permet pas d'appliquer une fonction à
une liste impropre.  Nous avons réglé le problème en créant des
fonctions qui permettent de passer d'une liste impropre à une liste
propre et vice versa.

\section{Mutability conversion}

Toutes les variables qui sont mutables sont remplacées par une paire
dont le car contient la valeur, les accès sont remplacés par des
appels à {\tt car}, et les appels à {\tt set!} sont remplacés par des
appels à {\tt set-car!}.

\section{Closure conversion}

Toutes les fonctions du programme sont modifiées de telle sorte
qu'elles prennent 2 paramètres supplémentaires:

\begin{itemize}
\item La fermeture lexicale qui contient toute les variables libres
\item Le nombre de paramètres actuels qui ont été passés à la fonction
  (nécessaire pour les paramètres reste)
\end{itemize}




\chapter{Environnement}

Dans un compilateur, il est nécessaire de faire la gestion de
l'environnement, un structure qui permet de garder la trace des
symboles qui sont accessibles ainsi que la façon d'y accéder. Dans
\sins{}, la gestion de l'environnement est faite dans le module {\it
  backend/env.scm}.

\section{Structures de données}

L'environnement est représentée par une liste deux éléments. Le
premier élément contient la distance en octets entre le prochain
symbole local qui sera ajouté et le début de la trame. Le second
élément est une liste de tuples contenant 3 informations:


\begin{verbatim}
(<symbole> <portée> <décalage>)
\end{verbatim}

Dans le cas d'une variable locale ou d'un paramètre de fonction, la
portée est représentée par le symbole {\it local} et le décalage est la
distance entre le début de la trame et l'emplacement en mémoire de la
valeur associée au symbole.

Dans le cas d'une variable globale, la portée est représentée par le
symbole {\it global} et au lieu d'un décallage, le troisième élément
du tuple est l'étiquette globale où se trouve la valeur associée au
symbole.

Voici les fonctions pour manipuler un environnement.

\begin{itemize}
\item {\bf make-env}: crée et retourne un environnement vide.
\item {\bf env-fs}: retourne la taille de la trame.
\item {\bf env-symbols}: retourne la liste des symboles.
\item {\bf env-fs++}: augmente d'un mot la taille de la trame et
  retourne le nouvel environnement modifié.
\item {\bf env-fs+}: augmente d'un nombre spécifique de mots la taille
  de la trame et retourne le nouvel environnement modifié.
\item {\bf env-add-symbol}: ajoute un symbole à la liste de symbole,
  incrémente la taille de la trame, et retourne le nouvel
  environnement modifié.
\item {\bf env-lookup}: tente de retourner le tuple d'un symbole. Si
  aucun tuple local est trouvé, on retourne le tuple d'une variable
  globale.
\item {\bf env-update}: fonction utilitaire qui ajoute une liste de
  symboles locaux dans l'environnement.
\end{itemize}





\chapter{Génération de code}

La génération de code est sans doute la partie la plus complexe de
\sins{}.  À partir d'un arbre de syntaxe abstraite et d'un
environnement (voir les chapîtres précédents pour plus de détails),
\sins{} génère le code assembleur x86 32-bits qui est sémantiquement
équivalent au programme Scheme.

\section{Constantes}

Dans le fichier {\it sins_const.h}, les valeurs des symboles \#t,
\#f et () sont définis; afin de simplifier l'utilisation de ces
valeurs dans la génération de code, nous les avons copié.  Ainsi, ces
trois symboles ont les valeurs 5, 1, et 2, respectivement.

\section{Variables}

Le module de génération de code possède une queue appelée {\tt
  delayed-functions}; à chaque fois qu'une expression lambda est
recontrée, on l'ajoute dans cette queue, et lorsque la génération de
code pour la fonction actuelle est terminée, on fait la génération de
code de la prochaine fonction dans la queue jusqu'à ce qu'elle soit
vide.

Le tableau {\tt primitive-funcs} sert à associer des symboles Scheme
avec les fonctions primitives écrites en C.  Le nombre d'argument
requis est également dans cette table.  L' appel des primitives est
géré différement de l'appel des fonctions.

La variable {\tt global-env} est passée de fonction en fonction et
contient les symboles locaux qui ont été définis.  Le chapître sur
l'environnement possède plus de détails à leurs sujets.



\section{Fonctions}

\subsection{gen-global-vars}

Cette fonction trouve toutes les variables globales (qui sont les
variables libres de l'expression {\tt begin} de plus haut niveau) et
crée des étiquettes où leurs valeurs seront sauvées.

\subsection{compile}

La fonction {\tt compile} est le chef d'orchestre du module de
génération de code; elle crée la fonction {\tt main}, initialise la
mémoire, insère les instructions assembleur des instructions de la
fonction principale, génère le code de toutes les autres fonctions et
insère le code pour les étiquettes des variables globales.


\subsection{compile-delayed-lambdas}

Cette fonction prend les expressions lambda de la queue {\tt
  delayed-functions} une-à-une et les compile.  Elle s'arrête lorsque
la queue est vide.


\subsection{compile-expr}

Étant donnée une expression et un environnement, la fonction {\tt
  compile-expr} examine la forme de l'expression pour déterminer
comment la compiler.

\subsection{compile-lambda}

Étant donné un symbole pour l'étiquette, une expression lambda et un
environnement, {\tt compile-lambda} mets à jour l'environnement avec
les paramètres de la fonction, pousse le registre {\tt ebp} sur la
pile et compile le corps de la fonction.

Dans le cas d'une fonction avec un paramètre reste, {\tt
  compile-lambda} va regrouper en une liste tous les paramètres qui ne
sont pas associés à des paramètres formels fixes.

\subsection{delay-lambda}

Cette fonction crée un symbole unique pour la lambda (qui sera utilisé
par {\tt compile-function} comme étiquette), et ajoute la fonction à
la queue {\tt delayed-functions}.  L'adresse de l'étiquette est mise
dans le registre {\tt eax} afin de pouvoir manipuler la lambda dans le
corps où elle a été créée.

\subsection{compile-let}

Cette fonction pousse sur la pile le résultat de la compilation des
expressions dans ses définitions, met l'environnement à jour et
exécute le corps de l'expression {\tt let} avec ce nouvel
environnement.  À la sortie du corps, les éléments qui ont été poussés
sur la pile sont dépilés.

\subsection{compile-if}

Cette fonction fait la compilation d'une expression {\tt if}. Les
trois expressions (condition, conséquent, alternative) sont compilées
et le résultat de la condition est comparé avec la valeur \#f. Si la
comparaison est vraie (donc que la condition est fausse), on fait un
saut à l'étiquette {\it else}. Si la comparaison est fausse (donc que
la condition est vraie), on fait l'exécution du code du conséquent
suivit d'un saut qui nous amène à la fin des instructions du {\tt if}.

\subsection{gen-number}

Cette fonction prend en paramètre un nombre, l'emboîte et la tranfère
dans {\tt eax}. Afin d'améliorer légèrement la performance du code
généré, l'emboîtement est fait manuellement, à la compilation par une
multiplication par 4 plutôt que d'appeler la fonction primitive C
d'emboîtement à l'exécution.

\subsection{gen-bool}

Cette fonction assigne la valeur numérique associée à \#f ou \#t dans
le registre {\tt eax}.

\subsection{gen-char}

Cette fonction pousse le code ASCII d'un charactère sur la pile et
fait un appel à la primitive {\tt __integerToChar} afin d'emboîter le
caractère.

\subsection{gen-bool}

Cette fonction assigne la valeur numérique associée à () dans le
registre {\tt eax}.

\subsection{gen-variable-access}

Étant donné un symbole et un environnement, cette fonction effectue
une recherche dans l'environnement du symbole.

Si le symbole trouvé est local, l'instruction faisant un déplacement
entre une valeur sur la pile et le registre {\tt eax} est générée.

Si le symbole trouvé est global, l'instruction faisant un déplacement
entre une étiquette et le registre {\tt eax} est générée.

\subsection{push-args}

Cette fonction est utilisée par {\tt gen-fun-call} et {\tt
  gen-prim-call}.  Elle pousse, de droite à gauche, les arguments d'un
appel de fonction.

\subsection{gen-fun-call}

Cette fonction génère un appel de fonction Scheme; les arguments sont
poussés sur la pile (via {\tt push-args}), l'expression fonctionnelle
est compilée et appelée.

\subsection{gen-prim-call}

Cette fonction génère un appel d'une primitive (fonction dont le nom
commence par \%).  Les arguments sont poussés sur la pile (via {\tt
  push-args}), puis -- afin de respecter le protocole d'appel -- le
nombre de paramètres est poussé, suivit de () (car les primitives
n'ont pas de fermeture).  Finalement, l'appel de l'étiquette de la
primitive est généré.

\subsection{compile-set!}

Les définitions sont remplacées par des assignations; pour se faire,
on compile le corps de la définition et on assigne le résultat à
l'adresse de l'étiquette globale du symbole.

\subsection{gen-make-closure}

Un ``appel'' à la fonction {\tt make-closure} est traité spécialement
dans le compilateur.  Il existe 5 primitives en C pour la gestion des
lambda:

\begin{itemize}
\item {\bf __createLambda:} crée un objet lambda capable de stocker le
  pointeur de fonction et toutes la variables libres.
\item {\bf __lambdaSet:} assigne une valeur à une des cellules pour
  les variables libres.
\item {\bf __lambdaSetCode:} assigne l'adresse du code de la fonction.
\item {\bf __lambdaRef:} accéde à une variable libre.
\item {\bf __lambdaGetCode:} accède à l'adresse du code de la fonction.
\end{itemize}

Lors d'un appel de {\tt make-closure}, on crée un nouvel objet lambda,
et on assigne aux différentes cellules l'adresse du code et les
variables libres.


\subsection{gen-closure-code}

Cette fonction transfère dans le registre {\tt eax} l'adresse du code
d'une fermeture.


\subsection{gen-closure-ref}

Cette fonction transfère dans le registre {\tt eax} la valeur d'une
variable libre.



\chapter{Problèmes et solutions}

\section{Analyse lexicale}

L'analyse lexicale a probablement été la partie la plus facile à
compléter. L'implantation suit de très près la théorie sur les
automates à états finis et a été complétée et testée sans anicroche.

\section{Analyse syntaxique}

Une difficulté rencontrée dans l'analyse syntaxique a été la gestion
de la valeur fausse (\#f).  En effet, il était initialement impossible
de distinguer entre la valeur \#f lue lors de l'analyse lexicale et la
valeur logique fausse.  Ainsi, un code comme ceci pouvait causer
problème:


\begin{verbatim}
(define (<literal> ast)
  (and (or (<quotation> ast)
           (<self-evaluating> ast))
       ast))
\end{verbatim}

Cette fonction est utilisée pour lire un litéral Scheme, dont \#f fait
partie.  Cette fonction doit retourner l'arbre de syntaxe abstraite,
mais comme celui-ci est \#f la fonction appelante n'a aucune façon de
savoir si {\tt <literal>} a retourné \#f parce que c'est le litéral
qui a été lu ou parce qu'il y a une erreur.

Afin de régler ce problème, nous avons procédé en 2 étapes:

\begin{enumerate}
\item Dans la phase d'analyse lexicale, nous avons remplacé le lexème
  pour la valeur fausse de {\tt (boolean . \#f)} à {\tt ('boolean .
    false)} où {\tt false} est un symbole unique généré par le
  compilateur.
\item Dans la phase d'analyse syntaxique, après que l'arbre est
  généré, nous le parcourons et transformons toutes les feuilles {\tt
    false} par \#f.
\end{enumerate}

\section{Génération de code}

\subsection{Paramètre reste}

En Scheme, on peut définir des fonctions qui prennent un nombre
variable de paramètres des façons suivantes:

\begin{verbatim}
(lambda args ...) ;; Tous les paramètres sont optionnels
(lambda (a1 a2 . rest) ...) ;; a1 et a2 sont obligatoires
\end{verbatim}

Réussir à faire fonctionner ces appels de fonction a été plus
difficile que la tâche peut le sembler.

Dans un premier temps, il est impossible à la compilation de savoir
combien de paramètres actuels ont été envoyés.  Afin de connaître
cette information, un paramètre supplémentaire est envoyé à la lambda,
le nombre de paramètres actuels.  Donc, la signature des deux
fonctions ci-haut est changée ainsi:

\begin{verbatim}
(lambda ($clo $num . args) ...)
(lambda ($clo $num a1 a2 . rest) ...)
\end{verbatim}

Maintenant qu'on connait le nombre de paramètres actuels, on peut
regrouper dans une liste tous les arguments qui ne sont pas associés
à un paramètre ``fixe''.  Voici comment on procède:

\begin{enumerate}
\item On fait la différence entre le nombre de paramètres actuels et
  le nombre de paramètres formels.
\item On crée une boucle qui construira la liste des arguments restants.
\item Une fois que la liste est créée, on l'insère dans la pile à
  l'emplacement du premier paramètre restant.  En faisant ce
  remplacement, lors des accès au paramètre reste, l'environnement
  trouvera la liste au bon emplacement.
\end{enumerate}

Bien que la stratégie soit simple, la gestion des différents détails
d'implantation a fait en sorte que la complétion de cette
fonctionnalité a pris environ 5 heures.




\appendix
\chapter{Grammaire}
\label{grammaire}
Voici une description EBNF de la grammaire supportée par \sins{}. Au
moment d'écrire le rapport de la première remise, \sins{} ne
supportait pas encore les abbréviations complétement mais nous avons
choisi de l'inclure dans la description malgré tout. Cette grammaire
évoluera probablement au cours du projet.

\setlength{\grammarindent}{3em}


\section{Lexèmes}
\label{grammar-tokens}
\begin{grammar}
  <alpha> $\longrightarrow$ `a..zA..Z'

  <digit> $\longrightarrow$ `0..9'

  <boolean> $\longrightarrow$ `\#f' | `\#t'

  <extended> $\longrightarrow$ `!' | `\$' | `\%' | `\&' | `*' | `+' | `-' | `.' | `/' | `:'
  | `<' | `=' | `>' | `?' | `@' | `\textasciicircum' | `\_' | `\textasciitilde'

  <number> $\longrightarrow$ <digit> <digit>*

  <identifier> $\longrightarrow$ (<alpha> | <extended>) (<alpha> | <extended> |
  <digit>)*

  <keyword> $\longrightarrow$ `define' | `else' | `unquote' | `unquote-splicing' | `quote'
  \alt `lambda' | `if' | `set!' | `begin' | `cond' | `and' | `or'
  \alt `case' | `let' | `let*' | `letrec' | `do' | `delay' |
  `quasiquote'

  <string> $\longrightarrow$ `\textquotedbl' <characters>* `\textquotedbl'

  <character> $\longrightarrow$ `#\textbackslash' ( <any character> | `nul' |
  `newline' | `space' | `tab' )

\end{grammar}



\section{datum}
\begin{grammar}
  <datum> $\longrightarrow$ <simple datum> \alt <compound datum>

  <simple datum> $\longrightarrow$ <boolean> \alt <number>
  \alt <character> \alt <string> \alt <symbol>

  <symbol> $\longrightarrow$ <identifier>

  <compound datum> $\longrightarrow$ <list>

  <list> $\longrightarrow$ \bop <datum>* \bcp \alt \bop <datum>+  .  <datum> \bcp
  \alt <abbreviation>

  <abbreviation> $\longrightarrow$ <abbrev prefix> <datum>

  <abbrev prefix> $\longrightarrow$ \'{} \alt \`{} \alt , \alt ,@

\end{grammar}

\section{program}

\begin{grammar}
  <program> $\longrightarrow$ <command or definition>*

  <command or definition> $\longrightarrow$ <command>
  \alt <definition>
  \alt \bop \textbf{begin} <command or definition>+ \bcp

  <definition> $\longrightarrow$ \bop define <variable> <expression> \bcp
  \alt \bop \textbf{define} \bop <variable> <def formals> \bcp <body> \bcp
  \alt \bop \textbf{begin} <definition>* \bcp

  <def formals> $\longrightarrow$ <variable>*
  \alt <variable>*  .  <variable>
\end{grammar}

\section{expression}

\begin{grammar}
  <expression> $\longrightarrow$ <variable>
  \alt <literal>
  \alt <procedure call>
  \alt <lambda expression>
  \alt <conditional>
  \alt <assignment>
  \alt <derived expression>

  <literal> $\longrightarrow$ <quotation> \alt <self-evaluating>

  <self-evaluating> $\longrightarrow$ <boolean> \alt <number>
  \alt <character> \alt <string>

  <quotation> $\longrightarrow$ '<datum> \alt \bop quote <datum> \bcp

  <procedure call> $\longrightarrow$ \bop <operator> <operand>* \bcp

  <operator> $\longrightarrow$ <expression>

  <operand> $\longrightarrow$ <expression>

  <lambda expression> $\longrightarrow$ \bop lambda <formals> <body> \bcp

  <formals> $\longrightarrow$ \bop <variable>* \bcp \alt <variable>
  \alt \bop <variable>+  .  <variable> \bcp

  <body> $\longrightarrow$ <definition>* <sequence>

  <sequence> $\longrightarrow$ <command>* <expression>

  <command> $\longrightarrow$ <expression>

  <conditional> $\longrightarrow$ \bop \textbf{if} <test> <consequent> <alternate> \bcp

  <test> $\longrightarrow$ <expression>

  <consequent> $\longrightarrow$ <expression>

  <alternate> $\longrightarrow$ <expression> \alt <empty>

  <assignment> $\longrightarrow$ \bop \textbf{set!} <variable> <expression> \bcp

  <derived expression> $\longrightarrow$ \bop cond <cond clause>+ \bcp
  \alt \bop \textbf{cond} <cond clause>* \bop else <sequence> \bcp \bcp
  \alt \bop \textbf{and} <test>* \bcp
  \alt \bop \textbf{or} <test>* \bcp
  \alt \bop \textbf{let} \bop <binding spec>* \bcp <body> \bcp
  \alt \bop \textbf{let} <variable> \bop <binding spec>* \bcp <body> \bcp
  \alt \bop \textbf{let*} \bop <binding spec>* \bcp <body> \bcp
  \alt \bop \textbf{letrec} \bop <binding spec>* \bcp <body> \bcp
  \alt \bop \textbf{begin} <sequence> \bcp
  \alt <quasiquotation>

  <cond clause> $\longrightarrow$ \bop <test> <sequence> \bcp
  \alt \bop <test> \bcp
  \alt \bop <test> => <recipient> \bcp

  <recipient> $\longrightarrow$ <expression>


  <binding spec> $\longrightarrow$ \bop <variable> <expression> \bcp

\end{grammar}

\section{quasiquotation}
\begin{grammar}
  <quasiquotation> $\longrightarrow$ \`{}<expression>
  \alt \bop \textbf{quasiquote} <expression> \bcp
\end{grammar}

\end{document}
